{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9z_Q__q9MeBd",
        "outputId": "81e1ecfb-4a58-422c-8c83-53f17197a754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.25.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://64cd00bcbc01f07ce3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://64cd00bcbc01f07ce3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7867, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install gradio\n",
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Sample Cricket Match Data (REPLACE WITH YOUR ACTUAL DATA) ---\n",
        "data = {\n",
        "    'TeamA': ['India', 'Australia', 'England', 'India', 'South Africa', 'Australia', 'England', 'India', 'New Zealand', 'Australia'],\n",
        "    'TeamB': ['Australia', 'England', 'India', 'South Africa', 'England', 'India', 'Australia', 'New Zealand', 'England', 'South Africa'],\n",
        "    'Venue': ['Home', 'Away', 'Neutral', 'Home', 'Away', 'Neutral', 'Home', 'Away', 'Neutral', 'Home'],\n",
        "    'Toss_Won_A': [1, 0, 1, 1, 0, 1, 0, 1, 0, 1],  # 1 if Team A won the toss, 0 otherwise\n",
        "    'TeamA_Rank': [1, 2, 3, 1, 4, 2, 3, 1, 5, 2],\n",
        "    'TeamB_Rank': [2, 3, 1, 4, 3, 1, 2, 5, 3, 4],\n",
        "    'Head_to_Head_Wins_A': [3, 2, 1, 4, 0, 2, 1, 5, 1, 3],\n",
        "    'Recent_Form_A': [0.8, 0.6, 0.7, 0.9, 0.5, 0.75, 0.65, 0.92, 0.58, 0.88],  # Win percentage in last 5 matches\n",
        "    'Recent_Form_B': [0.7, 0.55, 0.8, 0.6, 0.75, 0.88, 0.5, 0.65, 0.72, 0.6],\n",
        "    'Win_A': [1, 0, 0, 1, 0, 1, 1, 1, 0, 1]  # 1 if Team A won, 0 if Team B won\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "label_encoders = {}\n",
        "for column in ['TeamA', 'TeamB', 'Venue']:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df[['TeamA', 'TeamB', 'Venue', 'Toss_Won_A', 'TeamA_Rank', 'TeamB_Rank', 'Head_to_Head_Wins_A', 'Recent_Form_A', 'Recent_Form_B']]\n",
        "y = df['Win_A']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_features = ['TeamA_Rank', 'TeamB_Rank', 'Head_to_Head_Wins_A', 'Recent_Form_A', 'Recent_Form_B']\n",
        "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
        "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
        "\n",
        "# --- Train the Logistic Regression model ---\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Prediction Function for Gradio ---\n",
        "def predict_winner(team_a, team_b, venue, toss_won_a, team_a_rank, team_b_rank, head_to_head_wins_a, recent_form_a, recent_form_b):\n",
        "    try:\n",
        "        # Encode categorical inputs\n",
        "        team_a_encoded = label_encoders['TeamA'].transform([team_a])[0]\n",
        "        team_b_encoded = label_encoders['TeamB'].transform([team_b])[0]\n",
        "        venue_encoded = label_encoders['Venue'].transform([venue])[0]\n",
        "\n",
        "        input_data = pd.DataFrame({\n",
        "            'TeamA': [team_a_encoded],\n",
        "            'TeamB': [team_b_encoded],\n",
        "            'Venue': [venue_encoded],\n",
        "            'Toss_Won_A': [toss_won_a],\n",
        "            'TeamA_Rank': [team_a_rank],\n",
        "            'TeamB_Rank': [team_b_rank],\n",
        "            'Head_to_Head_Wins_A': [head_to_head_wins_a],\n",
        "            'Recent_Form_A': [recent_form_a],\n",
        "            'Recent_Form_B': [recent_form_b]\n",
        "        })\n",
        "\n",
        "        # Scale numerical inputs\n",
        "        numerical_features = ['TeamA_Rank', 'TeamB_Rank', 'Head_to_Head_Wins_A', 'Recent_Form_A', 'Recent_Form_B']\n",
        "        input_data[numerical_features] = scaler.transform(input_data[numerical_features])\n",
        "\n",
        "        probability = model.predict_proba(input_data)[0][1]  # Probability of Team A winning\n",
        "        prediction = f\"{team_a} is likely to win\" if probability >= 0.5 else f\"{team_b} is likely to win\"\n",
        "        confidence = f\"{probability * 100:.2f}% probability for {team_a} to win.\"\n",
        "        return prediction, confidence\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {e}\", \"\"\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "iface = gr.Interface(\n",
        "    fn=predict_winner,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=list(label_encoders['TeamA'].classes_), label=\"Team A\"),\n",
        "        gr.Dropdown(choices=list(label_encoders['TeamB'].classes_), label=\"Team B\"),\n",
        "        gr.Dropdown(choices=list(label_encoders['Venue'].classes_), label=\"Venue\"),\n",
        "        gr.Radio([0, 1], label=\"Did Team A win the toss? (1=Yes, 0=No)\"),\n",
        "        gr.Number(label=\"Team A Rank (Lower is better)\"),\n",
        "        gr.Number(label=\"Team B Rank (Lower is better)\"),\n",
        "        gr.Number(label=\"Head-to-Head Wins for Team A\"),\n",
        "        gr.Slider(0, 1, step=0.01, label=\"Recent Form of Team A (Win Percentage)\"),\n",
        "        gr.Slider(0, 1, step=0.01, label=\"Recent Form of Team B (Win Percentage)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Prediction\"),\n",
        "        gr.Textbox(label=\"Confidence\")\n",
        "    ],\n",
        "    title=\"Cricket Match Winner Predictor (Logistic Regression)\",\n",
        "    description=\"Predict the likely winner of a cricket match based on team statistics and match conditions.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(share=False)\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., cricket_predictor_lr.py).\n",
        "# 2. Run it in your Python environment (you'll need pandas, scikit-learn, and gradio installed: pip install pandas scikit-learn gradio).\n",
        "# 3. A Gradio interface will open in your web browser.\n",
        "# 4. Select the teams, venue, toss result, and enter their ranks and recent form.\n",
        "# 5. Click the \"Submit\" button to get the prediction.\n",
        "\n",
        "# --- How to Use ---\n",
        "# - Select the participating teams (Team A and Team B).\n",
        "# - Choose the venue of the match.\n",
        "# - Indicate whether Team A won the toss (1 for Yes, 0 for No).\n",
        "# - Enter the current rankings of both teams (lower rank is generally better).\n",
        "# - Provide the number of head-to-head wins for Team A against Team B.\n",
        "# - Enter the recent form of both teams as a win percentage (a value between 0 and 1).\n",
        "# - The output will show the predicted winner and the confidence level (probability of Team A winning).\n",
        "\n",
        "# --- Important Notes ---\n",
        "# - **Replace the sample data with your actual cricket match data for a meaningful model.** The more data you have, the better the model's performance is likely to be.\n",
        "# - The features used here are just examples. You might want to include more relevant features like player statistics, pitch conditions, weather, etc., to improve prediction accuracy.\n",
        "# - The performance of the Logistic Regression model depends heavily on the quality and relevance of the input data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# --- Load the Iris Dataset ---\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame\n",
        "\n",
        "# --- Separate Features (X) and Target (y) ---\n",
        "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
        "y = df['target']\n",
        "target_names = iris.target_names\n",
        "\n",
        "# --- Split Data into Training and Testing Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Scale Numerical Features ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- Train the K-Nearest Neighbors (KNN) Model ---\n",
        "n_neighbors = 5  # You can experiment with different values of k\n",
        "model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# --- Prediction Function for Gradio ---\n",
        "def predict_flower_species(sepal_length, sepal_width, petal_length, petal_width):\n",
        "    try:\n",
        "        input_data = pd.DataFrame({\n",
        "            'sepal length (cm)': [sepal_length],\n",
        "            'sepal width (cm)': [sepal_width],\n",
        "            'petal length (cm)': [petal_length],\n",
        "            'petal width (cm)': [petal_width]\n",
        "        })\n",
        "\n",
        "        # Scale the input data using the same scaler fitted on the training data\n",
        "        input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "        prediction = model.predict(input_data_scaled)[0]\n",
        "        probability = model.predict_proba(input_data_scaled)[0]\n",
        "\n",
        "        predicted_species = target_names[prediction]\n",
        "        confidence = f\"Probabilities: {', '.join([f'{name}: {prob * 100:.2f}%' for name, prob in zip(target_names, probability)])}\"\n",
        "\n",
        "        return predicted_species, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {e}\", \"\"\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "iface = gr.Interface(\n",
        "    fn=predict_flower_species,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Sepal Length (cm)\"),\n",
        "        gr.Number(label=\"Sepal Width (cm)\"),\n",
        "        gr.Number(label=\"Petal Length (cm)\"),\n",
        "        gr.Number(label=\"Petal Width (cm)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Predicted Flower Species\"),\n",
        "        gr.Textbox(label=\"Confidence\")\n",
        "    ],\n",
        "    title=\"Iris Flower Species Predictor (K-Nearest Neighbors)\",\n",
        "    description=\"Enter the sepal and petal measurements of an iris flower to predict its species using a K-Nearest Neighbors model.\"\n",
        ")\n",
        "\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., iris_predictor_knn.py).\n",
        "# 2. Run it in your Python environment (you'll need pandas, scikit-learn, and gradio installed: pip install pandas scikit-learn gradio).\n",
        "# 3. A Gradio interface will open in your web browser.\n",
        "# 4. Enter the sepal and petal measurements in the input fields.\n",
        "# 5. Click the \"Submit\" button to get the predicted flower species and the probabilities for each class.\n",
        "\n",
        "# --- How to Use ---\n",
        "# - Enter the sepal length (in cm).\n",
        "# - Enter the sepal width (in cm).\n",
        "# - Enter the petal length (in cm).\n",
        "# - Enter the petal width (in cm).\n",
        "# - Click the \"Submit\" button.\n",
        "# - The output will show the predicted flower species (setosa, versicolor, or virginica) and the probabilities for each of these species based on the KNN model.\n",
        "\n",
        "# --- Important Notes ---\n",
        "# - The Iris dataset is a classic dataset for classification.\n",
        "# - The `n_neighbors` parameter in the `KNeighborsClassifier` determines how many neighboring data points are considered for prediction. You can experiment with different values of k.\n",
        "# - Feature scaling (`StandardScaler`) is important for KNN as it relies on distance calculations. Features with larger scales could disproportionately influence the results if not scaled."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "cImgT8baS6Po",
        "outputId": "1137ffb7-817b-4891-e826-a1b47e8e37b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cef5ab630f57e34118.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cef5ab630f57e34118.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "# --- Sample Event Data (REPLACE WITH YOUR ACTUAL DATA) ---\n",
        "data = {\n",
        "    'Attendees': [150, 200, 180, 300, 120, 250, 220, 160, 280, 190],\n",
        "    'Budget': [5000, 8000, 6500, 12000, 4000, 9500, 7500, 5500, 11000, 7000],\n",
        "    'Duration_Days': [1, 2, 1, 3, 1, 2, 2, 1, 3, 1],\n",
        "    'Marketing_Spend': [1000, 1500, 1200, 2000, 800, 1800, 1400, 900, 2200, 1300],\n",
        "    'Feedback_Score': [4.2, 4.8, 4.5, 4.9, 3.8, 4.7, 4.6, 4.3, 4.9, 4.4],\n",
        "    'Social_Media_Engagement': [500, 800, 650, 1200, 300, 900, 750, 450, 1100, 600]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# --- Preprocessing: Scale Numerical Features ---\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=df.columns)\n",
        "\n",
        "# --- Function to Perform K-Means Clustering and Analyze ---\n",
        "def analyze_event_success(n_clusters):\n",
        "    try:\n",
        "        n_clusters = int(n_clusters)\n",
        "        if n_clusters <= 0:\n",
        "            return \"Number of clusters must be greater than 0.\", None\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "        clusters = kmeans.fit_predict(scaled_df)\n",
        "        clustered_df = df.copy()\n",
        "        clustered_df['Cluster'] = clusters\n",
        "\n",
        "        # Analyze cluster characteristics (mean values)\n",
        "        cluster_analysis = clustered_df.groupby('Cluster').mean()\n",
        "\n",
        "        # Visualize clusters (for 2 features - you can adapt for others)\n",
        "        if df.shape[1] >= 2:\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            scatter = plt.scatter(scaled_df.iloc[:, 0], scaled_df.iloc[:, 1], c=clusters, cmap='viridis')\n",
        "            plt.xlabel(df.columns[0])\n",
        "            plt.ylabel(df.columns[1])\n",
        "            plt.title(f'Event Clusters (K={n_clusters})')\n",
        "            plt.colorbar(scatter, label='Cluster')\n",
        "            plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='X', s=200, color='red', label='Centroids')\n",
        "            plt.legend()\n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "            plt.close()\n",
        "            image = f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Event Clusters\">'\n",
        "        else:\n",
        "            image = \"Cannot visualize clusters with less than 2 features.\"\n",
        "\n",
        "        cluster_table = cluster_analysis.to_html(float_format=\"%.2f\")\n",
        "\n",
        "        interpretation = \"Based on the cluster means, you can analyze which factors contribute to different event outcomes. For example, clusters with higher 'Feedback_Score' and 'Attendees' might represent more successful events.\"\n",
        "\n",
        "        return interpretation, image, cluster_table\n",
        "\n",
        "    except ValueError:\n",
        "        return \"Please enter a valid number for the number of clusters.\", None, None\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\", None, None\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_event_success,\n",
        "    inputs=gr.Slider(2, 5, 1, label=\"Number of Clusters (K)\"),  # Changed to positional arguments\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Cluster Interpretation\"),\n",
        "        gr.HTML(label=\"Cluster Visualization (First 2 Features)\"),\n",
        "        gr.HTML(label=\"Cluster Analysis (Mean Values)\")\n",
        "    ],\n",
        "    title=\"Event Success Analyzer (K-Means Clustering)\",\n",
        "    description=\"Analyze event data to identify patterns and factors contributing to success using K-Means clustering. Adjust the number of clusters to explore different groupings.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., event_analyzer_kmeans.py).\n",
        "# 2. Run it in your Python environment (you'll need pandas, scikit-learn, matplotlib, and gradio installed: pip install pandas scikit-learn matplotlib gradio).\n",
        "# 3. A Gradio interface will open in your web browser.\n",
        "# 4. Use the slider to select the desired number of clusters (K).\n",
        "# 5. Click the \"Submit\" button to perform the clustering and view the analysis.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "zcjfjBwQdDch",
        "outputId": "ed2a8822-120f-4426-eb72-d799486ac8bb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://92a2b2099f8548c7b6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://92a2b2099f8548c7b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "# --- Sample Customer Data (REPLACE WITH YOUR ACTUAL DATA) ---\n",
        "data = {\n",
        "    'CustomerID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "    'Avg_Spend': [50, 80, 60, 120, 40, 90, 70, 55, 110, 65, 95, 75, 100, 45, 85],\n",
        "    'Frequency': [5, 10, 7, 15, 3, 12, 8, 6, 14, 9, 11, 8, 13, 4, 10],\n",
        "    'Recency_Days': [30, 10, 20, 5, 45, 8, 15, 25, 7, 18, 12, 22, 9, 35, 16],\n",
        "    'Satisfaction': [4, 5, 4, 5, 3, 5, 4, 4, 5, 4, 5, 4, 5, 3, 4]\n",
        "}\n",
        "df = pd.DataFrame(data).set_index('CustomerID')\n",
        "\n",
        "# --- Preprocessing: Scale Numerical Features ---\n",
        "scaler = StandardScaler()\n",
        "scaled_df = scaler.fit_transform(df)\n",
        "\n",
        "def analyze_customer_groups(n_clusters_slider):\n",
        "    try:\n",
        "        n_clusters = int(n_clusters_slider)\n",
        "        if n_clusters <= 0:\n",
        "            return \"Number of clusters must be greater than 0.\", None, None\n",
        "\n",
        "        # Perform Agglomerative Clustering\n",
        "        agg_clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "        clusters = agg_clustering.fit_predict(scaled_df)\n",
        "        clustered_df = df.copy()\n",
        "        clustered_df['Cluster'] = clusters\n",
        "\n",
        "        # Analyze cluster characteristics (mean values)\n",
        "        cluster_analysis = clustered_df.groupby('Cluster').mean().to_html(float_format=\"%.2f\")\n",
        "\n",
        "        # Generate Dendrogram (for visualization of the hierarchy)\n",
        "        linked = linkage(scaled_df, 'ward')\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        dendrogram(linked, orientation='top', labels=df.index.tolist())\n",
        "        plt.title('Hierarchical Clustering Dendrogram')\n",
        "        plt.xlabel('Customer ID')\n",
        "        plt.ylabel('Distance')\n",
        "        buf = BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        image_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        plt.close()\n",
        "        image = f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Dendrogram\">'\n",
        "\n",
        "        interpretation = \"Based on the cluster means, you can understand the characteristics of different customer segments.\"\n",
        "\n",
        "        return interpretation, image, cluster_analysis\n",
        "\n",
        "    except ValueError:\n",
        "        return \"Please enter a valid number for the number of clusters.\", None, None\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\", None, None\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_customer_groups,\n",
        "    inputs=gr.Slider(2, 5, 1, label=\"Number of Clusters\"),  # Changed to positional arguments\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Cluster Interpretation\"),\n",
        "        gr.HTML(label=\"Dendrogram\"),\n",
        "        gr.HTML(label=\"Cluster Analysis (Mean Values)\")\n",
        "    ],\n",
        "    title=\"Retail Customer Grouping (Hierarchical Clustering)\",\n",
        "    description=\"Group retail customers based on their spending habits, frequency, recency, and satisfaction using Hierarchical Clustering.\"\n",
        ")\n",
        "\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., customer_clustering_hc.py).\n",
        "# 2. Run it in your Python environment (you'll need pandas, scikit-learn, scipy, matplotlib, and gradio installed: pip install pandas scikit-learn scipy matplotlib gradio).\n",
        "# 3. A Gradio interface will open in your web browser.\n",
        "# 4. Use the slider to select the desired number of clusters.\n",
        "# 5. Click the \"Submit\" button to perform the clustering and view the analysis.\n",
        "\n",
        "# --- How to Use ---\n",
        "# - Adjust the \"Number of Clusters\" slider to define how many customer segments you want to identify.\n",
        "# - The \"Dendrogram\" visualizes the hierarchical relationships between customers. The height of the branches indicates the distance between clusters.\n",
        "# - The \"Cluster Analysis\" table shows the average values of 'Avg_Spend', 'Frequency', 'Recency_Days', and 'Satisfaction' for each identified cluster. Analyze these means to understand the characteristics of each customer segment (e.g., high-spending frequent customers, low-spending infrequent customers, etc.).\n",
        "# - The \"Cluster Interpretation\" provides a general idea of how to analyze the results.\n",
        "\n",
        "# --- Important Notes ---\n",
        "# - **Replace the sample data with your actual retail customer data.** Ensure your data includes relevant features for customer segmentation.\n",
        "# - The number of clusters to choose is often a business decision or can be informed by analyzing the dendrogram (looking for significant increases in distance when merging clusters).\n",
        "# - Hierarchical clustering doesn't require you to specify the number of clusters beforehand, but in this Gradio interface, we're asking for it to provide concrete cluster groupings and analysis. You can explore the dendrogram to help decide on a suitable number of clusters.\n",
        "# - The 'ward' linkage method is used here, which tends to produce clusters of similar size. You can experiment with other linkage methods ('average', 'complete', 'single') depending on your data and desired cluster characteristics."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "LlYWqBxBeOPx",
        "outputId": "710bd38b-0876-4564-8364-9b73f67e4103"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3c521f2f9b02a96f35.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3c521f2f9b02a96f35.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Load and prepare the dataset (using CIFAR-10 as an example)\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Class names for CIFAR-10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Create the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model (with fewer epochs for quick demo)\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"\\nTest accuracy: {test_acc}\")\n",
        "\n",
        "# Function to classify an uploaded image\n",
        "def classify_image(inp):\n",
        "    # Convert the input to numpy array\n",
        "    inp = np.array(inp)\n",
        "    # Resize to 32x32 if needed\n",
        "    if inp.shape[0] != 32 or inp.shape[1] != 32:\n",
        "        inp = tf.image.resize(inp, (32, 32))\n",
        "    # Normalize and add batch dimension\n",
        "    inp = inp.reshape((-1, 32, 32, 3)) / 255.0\n",
        "    inp = tf.cast(inp, tf.float32)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(inp)[0]\n",
        "    return {class_names[i]: float(prediction[i]) for i in range(10)}\n",
        "\n",
        "# Create Gradio interface\n",
        "image = gr.Image()\n",
        "label = gr.Label(num_top_classes=3)\n",
        "\n",
        "title = \"CIFAR-10 Image Classifier\"\n",
        "description = \"A CNN model trained on CIFAR-10 to classify images into 10 categories. Upload any image and the model will try to classify it.\"\n",
        "\n",
        "iface = gr.Interface(fn=classify_image,\n",
        "                     inputs=image,\n",
        "                     outputs=label,\n",
        "                     title=title,\n",
        "                     description=description)\n",
        "\n",
        "# Launch the Gradio app in Colab\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xl-G98loe11f",
        "outputId": "cc3d9fc1-b2df-45cb-9974-38297d60f64e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 595/1563\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 53ms/step - accuracy: 0.2576 - loss: 1.9951"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2137, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1663, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 890, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-9-578b19d9790c>\", line 56, in analyze_sentiment\n",
            "    prediction = model.predict(padded_sequence, verbose=0)[0][0]\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\", line 272, in _adjust_input_rank\n",
            "    raise ValueError(\n",
            "ValueError: Exception encountered when calling Sequential.call().\n",
            "\n",
            "\u001b[1mInvalid input shape for input Tensor(\"sequential_7_1/Cast:0\", shape=(1, 100), dtype=float32). Expected shape (None, 32, 32, 3), but input has incompatible shape (1, 100)\u001b[0m\n",
            "\n",
            "Arguments received by Sequential.call():\n",
            "  • inputs=tf.Tensor(shape=(1, 100), dtype=int32)\n",
            "  • training=False\n",
            "  • mask=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 76ms/step - accuracy: 0.3464 - loss: 1.7729 - val_accuracy: 0.5460 - val_loss: 1.2488\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 66ms/step - accuracy: 0.5764 - loss: 1.1963 - val_accuracy: 0.6203 - val_loss: 1.0751\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 50ms/step - accuracy: 0.6401 - loss: 1.0257 - val_accuracy: 0.6526 - val_loss: 1.0013\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 51ms/step - accuracy: 0.6772 - loss: 0.9260 - val_accuracy: 0.6680 - val_loss: 0.9583\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 50ms/step - accuracy: 0.6994 - loss: 0.8511 - val_accuracy: 0.6760 - val_loss: 0.9514\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 50ms/step - accuracy: 0.7230 - loss: 0.7869 - val_accuracy: 0.6771 - val_loss: 0.9311\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.7423 - loss: 0.7411 - val_accuracy: 0.6996 - val_loss: 0.8833\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 50ms/step - accuracy: 0.7580 - loss: 0.6849 - val_accuracy: 0.6976 - val_loss: 0.9009\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 50ms/step - accuracy: 0.7739 - loss: 0.6457 - val_accuracy: 0.7058 - val_loss: 0.8660\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 50ms/step - accuracy: 0.7867 - loss: 0.6063 - val_accuracy: 0.7161 - val_loss: 0.8599\n",
            "313/313 - 4s - 11ms/step - accuracy: 0.7161 - loss: 0.8599\n",
            "\n",
            "Test accuracy: 0.7160999774932861\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://08a4d9b3d736297923.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://08a4d9b3d736297923.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# --- Sample Data (REPLACE WITH YOUR ACTUAL DATA) ---\n",
        "reviews = [\n",
        "    \"This movie was fantastic and I loved every moment!\",\n",
        "    \"Absolutely terrible, the acting was atrocious and the plot made no sense.\",\n",
        "    \"I really enjoyed the nuanced performances and the thought-provoking story.\",\n",
        "    \"The plot was confusing and the pacing was incredibly slow. I almost fell asleep.\",\n",
        "    \"A must-see film! The direction was brilliant and the cast was perfect.\",\n",
        "    \"Waste of my time and money. I wouldn't recommend this to anyone.\",\n",
        "    \"It had some good moments, but overall it was just okay.\",\n",
        "    \"The special effects were stunning, but the story was weak.\",\n",
        "    \"A truly captivating and emotional movie.\",\n",
        "    \"I found it boring and predictable.\"\n",
        "]\n",
        "sentiments = np.array([1, 0, 1, 0, 1, 0, 0.5, 0.5, 1, 0]) # 1 for positive, 0 for negative, 0.5 for neutral\n",
        "\n",
        "# --- Tokenization ---\n",
        "tokenizer = Tokenizer(num_words=1000) # Consider a larger num_words for a real dataset\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "\n",
        "# --- Padding ---\n",
        "maxlen = 100 # Choose a suitable max length based on your data\n",
        "padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "# --- Build the RNN Model ---\n",
        "embedding_dim = 16\n",
        "lstm_units = 32\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
        "    LSTM(lstm_units),\n",
        "    Dense(1, activation='sigmoid') # Sigmoid for binary sentiment (0 or 1)\n",
        "])\n",
        "\n",
        "# --- Compile the Model ---\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --- Train the Model ---\n",
        "model.fit(padded_sequences, sentiments, epochs=10, validation_split=0.2, verbose=0)\n",
        "\n",
        "# --- Prediction Function for Gradio (WITH DEBUGGING PRINTS) ---\n",
        "def analyze_sentiment(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    print(f\"Tokenized sequence: {sequence}\")\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=maxlen)\n",
        "    print(f\"Padded sequence shape: {padded_sequence.shape}\")\n",
        "    prediction = model.predict(padded_sequence, verbose=0)[0][0]\n",
        "    print(f\"Prediction score: {prediction}\")\n",
        "    sentiment = \"Positive\" if prediction >= 0.7 else \"Negative\" if prediction <= 0.3 else \"Neutral\"\n",
        "    confidence = f\"{prediction * 100:.2f}% (Positive)\" if sentiment == \"Positive\" else f\"{(1 - prediction) * 100:.2f}% (Negative)\" if sentiment == \"Negative\" else f\"{prediction * 100:.2f}% (Positive), {(1 - prediction) * 100:.2f}% (Negative)\"\n",
        "    return sentiment, confidence\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_sentiment,\n",
        "    inputs=gr.Textbox(label=\"Movie Review\"),\n",
        "    outputs=(gr.Textbox(label=\"Sentiment\"), gr.Textbox(label=\"Confidence\")),\n",
        "    title=\"Movie Review Sentiment Analyzer (RNN)\",\n",
        "    description=\"Enter a movie review to analyze its sentiment (Positive, Negative, or Neutral) using a simple Recurrent Neural Network (RNN).\"\n",
        ")\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., sentiment_rnn.py).\n",
        "# 2. Make sure you have TensorFlow and Gradio installed:\n",
        "#    pip install tensorflow gradio numpy\n",
        "# 3. Run the script from your terminal or Colab: python sentiment_rnn.py\n",
        "# 4. A Gradio interface will open in your web browser.\n",
        "# 5. Enter the paragraph that caused the error in the text box and click \"Submit\".\n",
        "# 6. **Look at the output in your console** for the printed token sequence and padded sequence shape. Share that output with me."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "VYOZ8RCz4bpE",
        "outputId": "51a4c50f-f9d7-4530-a6b9-eafb3abb7b32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8dcaf888a4e3eddfc4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8dcaf888a4e3eddfc4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(share=True)\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- Fixed Dataset for Training (REPLACE WITH YOUR ACTUAL DATA) ---\n",
        "data = {\n",
        "    'Age': [25, 32, 28, 40, 22, 35, 29, 31, 26, 38, 27, 33, 30, 42, 24],\n",
        "    'Education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'High School', 'Master', 'Associate', 'Bachelor', 'Master', 'PhD', 'Bachelor', 'Master', 'Associate', 'PhD', 'High School'],\n",
        "    'Income': [50000, 80000, 60000, 100000, 35000, 90000, 55000, 70000, 75000, 110000, 52000, 85000, 65000, 105000, 40000],\n",
        "    'Experience': [3, 7, 5, 12, 1, 9, 4, 6, 4, 15, 2, 8, 5, 13, 1],\n",
        "    'Credit_Score': [700, 780, 720, 850, 650, 820, 710, 760, 740, 880, 705, 790, 730, 860, 660],\n",
        "    'Applied': [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0],\n",
        "    'Accepted': [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# --- Data Preprocessing and Model Training ---\n",
        "label_encoder = LabelEncoder()\n",
        "df['Education_Encoded'] = label_encoder.fit_transform(df['Education'])\n",
        "\n",
        "X = df[['Age', 'Education_Encoded', 'Income', 'Experience', 'Credit_Score', 'Applied']]\n",
        "y = df['Accepted']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Gradio Interface for Prediction ---\n",
        "def predict_acceptance(age, education, income, experience, credit_score, applied):\n",
        "    education_encoded = label_encoder.transform([education])[0]\n",
        "\n",
        "    input_data = pd.DataFrame({\n",
        "        'Age': [age],\n",
        "        'Education_Encoded': [education_encoded],\n",
        "        'Income': [income],\n",
        "        'Experience': [experience],\n",
        "        'Credit_Score': [credit_score],\n",
        "        'Applied': [applied]\n",
        "    })\n",
        "\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    probability = model.predict_proba(input_data)[0][1]\n",
        "\n",
        "    acceptance_label = \"Likely Accepted\" if prediction == 1 else \"Likely Rejected\"\n",
        "    confidence = f\"{probability * 100:.2f}% probability of acceptance.\"\n",
        "\n",
        "    return acceptance_label, confidence\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_acceptance,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Age\"),\n",
        "        gr.Dropdown(choices=list(label_encoder.classes_), label=\"Education Level\"),\n",
        "        gr.Number(label=\"Annual Income\"),\n",
        "        gr.Number(label=\"Years of Experience\"),\n",
        "        gr.Number(label=\"Credit Score\"),\n",
        "        gr.Radio([0, 1], label=\"Did the applicant apply? (1=Yes, 0=No)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Application Status\"),\n",
        "        gr.Textbox(label=\"Acceptance Confidence\")\n",
        "    ],\n",
        "    title=\"Application Acceptance Predictor\",\n",
        "    description=\"Enter the details of a new applicant to predict their likelihood of acceptance.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(share=False)\n",
        "\n",
        "# --- Instructions to Run ---\n",
        "# 1. Save this code as a Python file (e.g., app_predictor.py).\n",
        "# 2. Run it in your Google Colab environment (or local Python environment).\n",
        "# 3. A Gradio interface will appear, providing a local URL.\n",
        "# 4. Enter the details of a new applicant in the input fields and click the \"Submit\" button.\n",
        "# 5. The predicted application status and confidence will be displayed.\n",
        "\n",
        "# --- How to Provide Input in Gradio (acting upon the trained model) ---\n",
        "# In the Gradio interface that opens:\n",
        "# - Enter the Age as a number.\n",
        "# - Select the Education Level from the dropdown (make sure it's one of the categories present in the training data).\n",
        "# - Enter the Annual Income as a number.\n",
        "# - Enter the Years of Experience as a number.\n",
        "# - Enter the Credit Score as a number.\n",
        "# - Select whether the applicant applied (1 for Yes, 0 for No).\n",
        "# - Click the \"Submit\" button.\n",
        "# - The \"Application Status\" and \"Acceptance Confidence\" outputs will show the prediction based on the model trained on the 'data' dictionary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "-nfUNBfXNsJv",
        "outputId": "5d6b99e2-9f75-4a32-96cc-b9234ef643d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://08a4d9b3d736297923.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://08a4d9b3d736297923.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}