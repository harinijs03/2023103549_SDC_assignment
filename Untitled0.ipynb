{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "vf9rTDAo9xVr",
        "outputId": "6c21e220-a705-485f-bc63-2dbce8805624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRunning Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://60287a291b5748875e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://60287a291b5748875e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q gradio scikit-learn\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate sample regression data (replace this with real housing dataset later)\n",
        "X, y = make_regression(n_samples=500, n_features=3, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction function\n",
        "def predict_price(feature1, feature2, feature3):\n",
        "    input_data = np.array([[feature1, feature2, feature3]])\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    return f\"Predicted House Price: ₹{prediction:.2f}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_price,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Feature 1 (e.g., Size in sqft)\"),\n",
        "        gr.Number(label=\"Feature 2 (e.g., Number of Bedrooms)\"),\n",
        "        gr.Number(label=\"Feature 3 (e.g., Age of House in years)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"🏠 House Price Predictor\",\n",
        "    description=\"Enter the details to predict house price using Linear Regression.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from UCI repository (direct link)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "\n",
        "# Download and extract the dataset if required (you can upload manually as well)\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# Download dataset\n",
        "urllib.request.urlretrieve(url, \"smsspamcollection.zip\")\n",
        "\n",
        "# Extract files\n",
        "with zipfile.ZipFile(\"smsspamcollection.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"smsspamcollection\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t', header=None, names=['label', 'text'])\n",
        "\n",
        "# Encode labels\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline: TF-IDF + Logistic Regression\n",
        "model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "preds = model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, preds)}\")\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_spam(message):\n",
        "    prediction = model.predict([message])[0]\n",
        "    return \"Spam\" if prediction == 1 else \"Not Spam\"\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_spam,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Enter an email message...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Spam Detection\",\n",
        "    description=\"This is an Email Spam Detection system using Logistic Regression. It classifies messages as spam or not.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "eu0Q5ntQAKwU",
        "outputId": "df347437-36b9-47af-aed6-300bd8eaedb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9695067264573991\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c2b3f1568a2ff31131.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c2b3f1568a2ff31131.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# More realistic (but still sample) cricket data\n",
        "data = {\n",
        "    'TeamA_Rank': [3, 1, 5, 2, 4, 1, 6, 3, 2, 5, 4, 1, 7, 3, 2, 6, 5, 1, 4, 3, 2, 7, 6, 5, 4, 3, 1, 2, 7, 6],\n",
        "    'TeamB_Rank': [6, 4, 2, 5, 1, 3, 1, 4, 7, 2, 3, 5, 2, 6, 1, 3, 4, 7, 1, 5, 6, 3, 2, 1, 7, 4, 5, 3, 1, 2],\n",
        "    'Venue_Home': [1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1],\n",
        "    'Head_to_Head_Wins_A': [7, 3, 2, 6, 1, 8, 0, 5, 4, 2, 3, 9, 1, 6, 5, 2, 4, 10, 2, 7, 6, 1, 3, 8, 0, 5, 9, 4, 1, 7],\n",
        "    'Recent_Form_A': [0.75, 0.88, 0.52, 0.79, 0.61, 0.92, 0.45, 0.70, 0.85, 0.58, 0.65, 0.95, 0.38, 0.72, 0.81, 0.55, 0.68, 0.98, 0.63, 0.77, 0.89, 0.41, 0.59, 0.83, 0.66, 0.74, 0.91, 0.80, 0.48, 0.57],\n",
        "    'Recent_Form_B': [0.48, 0.65, 0.81, 0.55, 0.78, 0.60, 0.90, 0.52, 0.71, 0.86, 0.59, 0.73, 0.88, 0.49, 0.62, 0.84, 0.56, 0.70, 0.82, 0.51, 0.76, 0.93, 0.64, 0.79, 0.87, 0.53, 0.69, 0.85, 0.46, 0.61],\n",
        "    'Win_A': [1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df[['TeamA_Rank', 'TeamB_Rank', 'Venue_Home', 'Head_to_Head_Wins_A', 'Recent_Form_A', 'Recent_Form_B']]\n",
        "y = df['Win_A']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', random_state=42) # Added solver for stability\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Function to predict the winner\n",
        "def predict_winner(team_a_rank, team_b_rank, venue_home, head_to_head_wins_a, recent_form_a, recent_form_b):\n",
        "    try:\n",
        "        input_data = pd.DataFrame({\n",
        "            'TeamA_Rank': [team_a_rank],\n",
        "            'TeamB_Rank': [team_b_rank],\n",
        "            'Venue_Home': [venue_home],\n",
        "            'Head_to_Head_Wins_A': [head_to_head_wins_a],\n",
        "            'Recent_Form_A': [recent_form_a],\n",
        "            'Recent_Form_B': [recent_form_b]\n",
        "        })\n",
        "        input_data_scaled = scaler.transform(input_data)\n",
        "        probability = model.predict_proba(input_data_scaled)[0][1]\n",
        "        prediction = \"Team A is likely to win\" if probability >= 0.5 else \"Team B is likely to win\"\n",
        "        confidence = f\"{probability * 100:.2f}% probability for Team A to win.\"\n",
        "        return prediction, confidence\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {e}\", \"\"\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_winner,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Team A Rank (Lower is better)\"),\n",
        "        gr.Number(label=\"Team B Rank (Lower is better)\"),\n",
        "        gr.Radio([0, 1], label=\"Is Team A playing at home? (1=Yes, 0=No)\"),\n",
        "        gr.Number(label=\"Head-to-Head Wins for Team A\"),\n",
        "        gr.Slider(0, 1, step=0.01, label=\"Recent Form of Team A (Win Percentage)\"),\n",
        "        gr.Slider(0, 1, step=0.01, label=\"Recent Form of Team B (Win Percentage)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Prediction\"),\n",
        "        gr.Textbox(label=\"Confidence\")\n",
        "    ],\n",
        "    title=\"Cricket Match Winner Predictor\",\n",
        "    description=\"Predict the likely winner of a cricket match based on team rankings, venue, head-to-head records, and recent form.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "H5kx4EuTBpKD",
        "outputId": "4c6fc25d-9ab4-4958-eeb8-cfc6f6b36b3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7865, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}